time nice ketos train -f binary  -o ./20231231/gpt/german_newspapers -d cuda:0 --lag 10 -r 0.0001 -B 4 -w 0 -s '[1,120,0,1 Cr3,3,32,1,1 Gn32 Mp2,2 Cr3,3,64,1,1 Gn64 Mp2,2,2,2 Cr3,3,128,1,1 Gn128 Mp2,2,2,2 Cr3,3,256,1,1 Gn256 Mp2,2,2,2 S1(1x0)1,3 Lbx256 Do0.2 Lbx256 Do0.2 Lbx256 Do0.2]' german_newspapers_2023_12.arrow
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
You are using a CUDA device ('NVIDIA RTX A4000 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
┏━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃    ┃ Name      ┃ Type                     ┃ Params ┃                 In sizes ┃                Out sizes ┃
┡━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ 0  │ val_cer   │ CharErrorRate            │      0 │                        ? │                        ? │
│ 1  │ val_wer   │ WordErrorRate            │      0 │                        ? │                        ? │
│ 2  │ net       │ MultiParamSequential     │  7.9 M │  [[1, 1, 120, 400], '?'] │   [[1, 264, 1, 25], '?'] │
│ 3  │ net.C_0   │ ActConv2D                │    320 │  [[1, 1, 120, 400], '?'] │ [[1, 32, 120, 400], '?'] │
│ 4  │ net.Gn_1  │ GroupNorm                │     64 │ [[1, 32, 120, 400], '?'] │ [[1, 32, 120, 400], '?'] │
│ 5  │ net.Mp_2  │ MaxPool                  │      0 │ [[1, 32, 120, 400], '?'] │  [[1, 32, 60, 200], '?'] │
│ 6  │ net.C_3   │ ActConv2D                │ 18.5 K │  [[1, 32, 60, 200], '?'] │  [[1, 64, 60, 200], '?'] │
│ 7  │ net.Gn_4  │ GroupNorm                │    128 │  [[1, 64, 60, 200], '?'] │  [[1, 64, 60, 200], '?'] │
│ 8  │ net.Mp_5  │ MaxPool                  │      0 │  [[1, 64, 60, 200], '?'] │  [[1, 64, 30, 100], '?'] │
│ 9  │ net.C_6   │ ActConv2D                │ 73.9 K │  [[1, 64, 30, 100], '?'] │ [[1, 128, 30, 100], '?'] │
│ 10 │ net.Gn_7  │ GroupNorm                │    256 │ [[1, 128, 30, 100], '?'] │ [[1, 128, 30, 100], '?'] │
│ 11 │ net.Mp_8  │ MaxPool                  │      0 │ [[1, 128, 30, 100], '?'] │  [[1, 128, 15, 50], '?'] │
│ 12 │ net.C_9   │ ActConv2D                │  295 K │  [[1, 128, 15, 50], '?'] │  [[1, 256, 15, 50], '?'] │
│ 13 │ net.Gn_10 │ GroupNorm                │    512 │  [[1, 256, 15, 50], '?'] │  [[1, 256, 15, 50], '?'] │
│ 14 │ net.Mp_11 │ MaxPool                  │      0 │  [[1, 256, 15, 50], '?'] │   [[1, 256, 7, 25], '?'] │
│ 15 │ net.S_12  │ Reshape                  │      0 │   [[1, 256, 7, 25], '?'] │  [[1, 1792, 1, 25], '?'] │
│ 16 │ net.L_13  │ TransposedSummarizingRNN │  4.2 M │  [[1, 1792, 1, 25], '?'] │   [[1, 512, 1, 25], '?'] │
│ 17 │ net.Do_14 │ Dropout                  │      0 │   [[1, 512, 1, 25], '?'] │   [[1, 512, 1, 25], '?'] │
│ 18 │ net.L_15  │ TransposedSummarizingRNN │  1.6 M │   [[1, 512, 1, 25], '?'] │   [[1, 512, 1, 25], '?'] │
│ 19 │ net.Do_16 │ Dropout                  │      0 │   [[1, 512, 1, 25], '?'] │   [[1, 512, 1, 25], '?'] │
│ 20 │ net.L_17  │ TransposedSummarizingRNN │  1.6 M │   [[1, 512, 1, 25], '?'] │   [[1, 512, 1, 25], '?'] │
│ 21 │ net.Do_18 │ Dropout                  │      0 │   [[1, 512, 1, 25], '?'] │   [[1, 512, 1, 25], '?'] │
│ 22 │ net.O_19  │ LinSoftmax               │  135 K │   [[1, 512, 1, 25], '?'] │   [[1, 264, 1, 25], '?'] │
└────┴───────────┴──────────────────────────┴────────┴──────────────────────────┴──────────────────────────┘
Trainable params: 7.9 M                                                                                                                                                                
Non-trainable params: 0                                                                                                                                                                
Total params: 7.9 M                                                                                                                                                                    
Total estimated model params size (MB): 31                                                                                                                                             
stage 0/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:56:08 • 0:00:00 15.31it/s val_accuracy: 0.987 val_word_accuracy: 0.934  early_stopping: 0/10 0.98657
stage 1/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:57:26 • 0:00:00 14.48it/s val_accuracy: 0.99 val_word_accuracy: 0.951  early_stopping: 0/10 0.98966
stage 2/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:58:58 • 0:00:00 14.20it/s val_accuracy: 0.991 val_word_accuracy: 0.957  early_stopping: 0/10 0.99089
stage 3/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:57:46 • 0:00:00 14.48it/s val_accuracy: 0.991 val_word_accuracy: 0.96  early_stopping: 0/10 0.99148
stage 4/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:58:43 • 0:00:00 13.63it/s val_accuracy: 0.992 val_word_accuracy: 0.963  early_stopping: 0/10 0.99219
stage 5/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:58:51 • 0:00:00 14.57it/s val_accuracy: 0.992 val_word_accuracy: 0.964  early_stopping: 0/10 0.99229
stage 6/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:58:56 • 0:00:00 13.41it/s val_accuracy: 0.993 val_word_accuracy: 0.965  early_stopping: 0/10 0.99257
stage 7/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:59:14 • 0:00:00 14.22it/s val_accuracy: 0.993 val_word_accuracy: 0.966  early_stopping: 0/10 0.99277
stage 8/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:57:20 • 0:00:00 14.38it/s val_accuracy: 0.993 val_word_accuracy: 0.967  early_stopping: 0/10 0.99284
stage 9/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:57:21 • 0:00:00 14.67it/s val_accuracy: 0.993 val_word_accuracy: 0.967  early_stopping: 0/10 0.99288
stage 10/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:58:21 • 0:00:00 14.70it/s val_accuracy: 0.993 val_word_accuracy: 0.968  early_stopping: 0/10 0.99317
stage 11/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:58:36 • 0:00:00 13.09it/s val_accuracy: 0.993 val_word_accuracy: 0.968  early_stopping: 1/10 0.99317
stage 12/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 1:00:46 • 0:00:00 14.51it/s val_accuracy: 0.993 val_word_accuracy: 0.968  early_stopping: 2/10 0.99317
stage 13/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:56:53 • 0:00:00 14.80it/s val_accuracy: 0.993 val_word_accuracy: 0.969  early_stopping: 0/10 0.99323
stage 14/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:56:41 • 0:00:00 14.99it/s val_accuracy: 0.993 val_word_accuracy: 0.968  early_stopping: 0/10 0.99326
stage 15/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:56:41 • 0:00:00 14.80it/s val_accuracy: 0.993 val_word_accuracy: 0.968  early_stopping: 1/10 0.99326
stage 16/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:56:44 • 0:00:00 14.63it/s val_accuracy: 0.993 val_word_accuracy: 0.969  early_stopping: 0/10 0.99327
stage 17/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:56:42 • 0:00:00 14.58it/s val_accuracy: 0.993 val_word_accuracy: 0.969  early_stopping: 0/10 0.99345
stage 18/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:57:42 • 0:00:00 14.83it/s val_accuracy: 0.993 val_word_accuracy: 0.969  early_stopping: 1/10 0.99345
stage 19/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:57:43 • 0:00:00 14.85it/s val_accuracy: 0.994 val_word_accuracy: 0.97  early_stopping: 0/10 0.99353
stage 20/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:56:46 • 0:00:00 14.61it/s val_accuracy: 0.993 val_word_accuracy: 0.969  early_stopping: 1/10 0.99353
stage 21/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:57:12 • 0:00:00 14.19it/s val_accuracy: 0.993 val_word_accuracy: 0.969  early_stopping: 2/10 0.99353
stage 22/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:58:22 • 0:00:00 14.09it/s val_accuracy: 0.993 val_word_accuracy: 0.969  early_stopping: 3/10 0.99353
stage 23/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 1:00:30 • 0:00:00 14.71it/s val_accuracy: 0.994 val_word_accuracy: 0.97  early_stopping: 0/10 0.99356
stage 24/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:57:27 • 0:00:00 15.03it/s val_accuracy: 0.993 val_word_accuracy: 0.969  early_stopping: 1/10 0.99356
stage 25/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:56:42 • 0:00:00 14.42it/s val_accuracy: 0.993 val_word_accuracy: 0.969  early_stopping: 2/10 0.99356
stage 26/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:57:46 • 0:00:00 14.44it/s val_accuracy: 0.993 val_word_accuracy: 0.969  early_stopping: 3/10 0.99356
stage 27/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:58:01 • 0:00:00 14.50it/s val_accuracy: 0.994 val_word_accuracy: 0.97  early_stopping: 4/10 0.99356
stage 28/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:58:45 • 0:00:00 14.54it/s val_accuracy: 0.993 val_word_accuracy: 0.969  early_stopping: 5/10 0.99356
stage 29/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:57:40 • 0:00:00 14.19it/s val_accuracy: 0.994 val_word_accuracy: 0.969  early_stopping: 6/10 0.99356
stage 30/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:58:45 • 0:00:00 13.70it/s val_accuracy: 0.994 val_word_accuracy: 0.969  early_stopping: 7/10 0.99356
stage 31/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:56:43 • 0:00:00 14.88it/s val_accuracy: 0.994 val_word_accuracy: 0.97  early_stopping: 8/10 0.99356
stage 32/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:56:29 • 0:00:00 14.86it/s val_accuracy: 0.994 val_word_accuracy: 0.97  early_stopping: 0/10 0.99357
stage 33/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:59:00 • 0:00:00 13.28it/s val_accuracy: 0.994 val_word_accuracy: 0.97  early_stopping: 0/10 0.99358
stage 34/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:57:43 • 0:00:00 15.01it/s val_accuracy: 0.994 val_word_accuracy: 0.97  early_stopping: 0/10 0.99360
stage 35/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:59:25 • 0:00:00 14.71it/s val_accuracy: 0.994 val_word_accuracy: 0.97  early_stopping: 1/10 0.99360
stage 36/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:57:10 • 0:00:00 14.92it/s val_accuracy: 0.994 val_word_accuracy: 0.97  early_stopping: 2/10 0.99360
stage 37/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:57:06 • 0:00:00 14.31it/s val_accuracy: 0.994 val_word_accuracy: 0.97  early_stopping: 0/10 0.99364
stage 38/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:57:20 • 0:00:00 13.65it/s val_accuracy: 0.994 val_word_accuracy: 0.97  early_stopping: 1/10 0.99364
stage 39/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:58:10 • 0:00:00 14.97it/s val_accuracy: 0.994 val_word_accuracy: 0.97  early_stopping: 2/10 0.99364
stage 40/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:57:05 • 0:00:00 14.74it/s val_accuracy: 0.994 val_word_accuracy: 0.97  early_stopping: 3/10 0.99364
stage 41/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:57:58 • 0:00:00 14.84it/s val_accuracy: 0.994 val_word_accuracy: 0.97  early_stopping: 4/10 0.99364
stage 42/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:56:26 • 0:00:00 13.70it/s val_accuracy: 0.994 val_word_accuracy: 0.97  early_stopping: 5/10 0.99364
stage 43/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:56:31 • 0:00:00 14.74it/s val_accuracy: 0.994 val_word_accuracy: 0.97  early_stopping: 0/10 0.99369
stage 44/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:56:08 • 0:00:00 14.99it/s val_accuracy: 0.994 val_word_accuracy: 0.97  early_stopping: 1/10 0.99369
stage 45/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 1:00:15 • 0:00:00 14.65it/s val_accuracy: 0.994 val_word_accuracy: 0.97  early_stopping: 2/10 0.99369
stage 46/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:57:55 • 0:00:00 14.42it/s val_accuracy: 0.994 val_word_accuracy: 0.97  early_stopping: 0/10 0.99370
stage 47/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:58:27 • 0:00:00 14.38it/s val_accuracy: 0.994 val_word_accuracy: 0.97  early_stopping: 1/10 0.99370
stage 48/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:58:55 • 0:00:00 14.74it/s val_accuracy: 0.994 val_word_accuracy: 0.971  early_stopping: 0/10 0.99371
stage 49/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:59:27 • 0:00:00 14.39it/s val_accuracy: 0.994 val_word_accuracy: 0.97  early_stopping: 1/10 0.99371
stage 50/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:59:13 • 0:00:00 14.28it/s val_accuracy: 0.994 val_word_accuracy: 0.971  early_stopping: 0/10 0.99372
stage 51/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:59:01 • 0:00:00 14.41it/s val_accuracy: 0.994 val_word_accuracy: 0.97  early_stopping: 1/10 0.99372
stage 52/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:58:44 • 0:00:00 14.40it/s val_accuracy: 0.994 val_word_accuracy: 0.97  early_stopping: 2/10 0.99372
stage 53/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:57:38 • 0:00:00 14.47it/s val_accuracy: 0.994 val_word_accuracy: 0.971  early_stopping: 3/10 0.99372
stage 54/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:57:31 • 0:00:00 14.33it/s val_accuracy: 0.994 val_word_accuracy: 0.97  early_stopping: 4/10 0.99372
stage 55/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:57:33 • 0:00:00 14.31it/s val_accuracy: 0.994 val_word_accuracy: 0.971  early_stopping: 0/10 0.99380
stage 56/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:57:26 • 0:00:00 14.73it/s val_accuracy: 0.994 val_word_accuracy: 0.971  early_stopping: 1/10 0.99380
stage 57/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:57:31 • 0:00:00 14.40it/s val_accuracy: 0.994 val_word_accuracy: 0.97  early_stopping: 2/10 0.99380
stage 58/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:56:36 • 0:00:00 15.01it/s val_accuracy: 0.994 val_word_accuracy: 0.97  early_stopping: 3/10 0.99380
stage 59/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:56:34 • 0:00:00 14.69it/s val_accuracy: 0.994 val_word_accuracy: 0.971  early_stopping: 0/10 0.99384
stage 60/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:56:37 • 0:00:00 14.88it/s val_accuracy: 0.994 val_word_accuracy: 0.97  early_stopping: 1/10 0.99384
stage 61/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:56:39 • 0:00:00 14.71it/s val_accuracy: 0.994 val_word_accuracy: 0.971  early_stopping: 2/10 0.99384
stage 62/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:56:35 • 0:00:00 14.78it/s val_accuracy: 0.994 val_word_accuracy: 0.971  early_stopping: 3/10 0.99384
stage 63/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:56:38 • 0:00:00 14.74it/s val_accuracy: 0.994 val_word_accuracy: 0.971  early_stopping: 4/10 0.99384
stage 64/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:56:36 • 0:00:00 14.83it/s val_accuracy: 0.994 val_word_accuracy: 0.971  early_stopping: 5/10 0.99384
stage 65/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:56:36 • 0:00:00 15.05it/s val_accuracy: 0.994 val_word_accuracy: 0.97  early_stopping: 6/10 0.99384
stage 66/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:56:37 • 0:00:00 14.84it/s val_accuracy: 0.994 val_word_accuracy: 0.971  early_stopping: 7/10 0.99384
stage 67/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:56:36 • 0:00:00 14.76it/s val_accuracy: 0.994 val_word_accuracy: 0.97  early_stopping: 8/10 0.99384
stage 68/∞ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50088/50088 0:56:55 • 0:00:00 14.55it/s val_accuracy: 0.994 val_word_accuracy: 0.97  early_stopping: 9/10 0.99384
